import streamlit as st
import OpenDartReader
import pandas as pd
import io
import zipfile
import re
import requests
import json
from bs4 import BeautifulSoup

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ê¸°ì—… ë³´ê³ ì„œ ì›í´ë¦­", 
    page_icon="âš¡", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

st.title("âš¡ ê¸°ì—… ë³´ê³ ì„œ ì›í´ë¦­ ë‹¤ìš´ë¡œë“œ (AI ìµœì í™” ë²„ì „)")

# --- 1. API í‚¤ ì„¤ì • ---
if 'api_key' not in st.session_state:
    if "dart_api_key" in st.secrets:
        st.session_state.api_key = st.secrets["dart_api_key"]
    else:
        st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. secrets.tomlì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

api_key = st.session_state.api_key

# --- 2. DART ì§ì ‘ ì ‘ì† í•¨ìˆ˜ (6ìë¦¬ ì¢…ëª©ì½”ë“œ ì§€ì› ì—…ê·¸ë ˆì´ë“œ) ---
@st.cache_data(ttl=600)
def fetch_report_list_direct(corp_query, start_date, end_date):
    try:
        dart = OpenDartReader(api_key)
        
        # ì…ë ¥ê°’ì´ 6ìë¦¬ ìˆ«ìì¸ì§€ íŒë‹¨
        if corp_query.isdigit() and len(corp_query) == 6:
            corp_list = dart.corp_codes
            target_row = corp_list[corp_list['stock_code'] == corp_query]
            if target_row.empty:
                return None, corp_query
            corp_code = target_row.iloc[0]['corp_code']
            actual_corp_name = target_row.iloc[0]['corp_name']
        else:
            corp_code = dart.find_corp_code(corp_query)
            actual_corp_name = corp_query
            
        if not corp_code:
            return None, corp_query
    except:
        return None, corp_query

    url = "https://opendart.fss.or.kr/api/list.json"
    params = {
        'crtfc_key': api_key,
        'corp_code': corp_code,
        'bgn_de': start_date,
        'end_de': end_date,
        'pblntf_ty': 'A',
        'page_count': 100
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://dart.fss.or.kr/',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'Connection': 'keep-alive'
    }

    try:
        resp = requests.get(url, params=params, headers=headers, timeout=10)
        data = resp.json()
        
        if data.get('status') == '000':
            df = pd.DataFrame(data['list'])
            return df, actual_corp_name
        else:
            return pd.DataFrame(), actual_corp_name 
    except Exception as e:
        raise Exception(f"ì ‘ì† ì‹¤íŒ¨: {str(e)}")

# --- 3. ë¶„ë¥˜ ë° í•„í„°ë§ ë¡œì§ ---
def classify_and_filter(df, selected_types):
    if df is None or len(df) == 0:
        return df

    df = df.copy()
    df = df.sort_values(by='rcept_dt', ascending=False).reset_index(drop=True)

    smart_types = []
    for idx, row in df.iterrows():
        nm = row['report_nm']
        dt = row['rcept_dt']
        month = int(dt[4:6]) 
        
        r_type = "ê¸°íƒ€"
        if "ì‚¬ì—…ë³´ê³ ì„œ" in nm: r_type = "ì‚¬ì—…ë³´ê³ ì„œ"
        elif "ë°˜ê¸°ë³´ê³ ì„œ" in nm: r_type = "ë°˜ê¸°ë³´ê³ ì„œ"
        elif "ë¶„ê¸°ë³´ê³ ì„œ" in nm:
            if "1ë¶„ê¸°" in nm: r_type = "1ë¶„ê¸°ë³´ê³ ì„œ"
            elif "3ë¶„ê¸°" in nm: r_type = "3ë¶„ê¸°ë³´ê³ ì„œ"
            elif 4 <= month <= 6: r_type = "1ë¶„ê¸°ë³´ê³ ì„œ"
            elif 9 <= month <= 12: r_type = "3ë¶„ê¸°ë³´ê³ ì„œ"
            else: r_type = "ë¶„ê¸°ë³´ê³ ì„œ(ê¸°íƒ€)"
        smart_types.append(r_type)

    df['smart_type'] = smart_types
    
    filtered_df = df[df['smart_type'].isin(selected_types)].copy()
    
    if not filtered_df.empty:
        filtered_df['year_key'] = filtered_df['rcept_dt'].str[:4]
        final_df = filtered_df.drop_duplicates(subset=['smart_type', 'year_key'], keep='first')
        return final_df.drop(columns=['year_key'])
    else:
        return filtered_df

# --- 4. í…ìŠ¤íŠ¸ ë³€í™˜ í•¨ìˆ˜ (í† í° ì ˆì•½ ë¡œì§ ì´ì‹ ì™„ë£Œ) ---
def extract_ai_friendly_text(html_content):
    soup = BeautifulSoup(html_content, "html.parser")
    for s in soup(["script", "style", "head", "svg", "img"]):
        s.decompose()
        
    for nav in soup.find_all(text=re.compile(r"ë³¸ë¬¸\s*ìœ„ì¹˜ë¡œ\s*ì´ë™|ëª©ì°¨|TOP")):
        nav.extract()

    for table in soup.find_all("table"):
        rows = []
        headers = [th.get_text(strip=True) for th in table.find_all("th")]
        if headers:
            rows.append("| " + " | ".join(headers) + " |")
            rows.append("| " + " | ".join(["---"] * len(headers)) + " |")
        for tr in table.find_all("tr"):
            cells = [td.get_text(strip=True) for td in tr.find_all("td")]
            if cells:
                rows.append("| " + " | ".join(cells) + " |")
        if rows:
            table_md = "\n" + "\n".join(rows) + "\n"
            table.replace_with(table_md)
            
    raw_text = soup.get_text(separator="\n")
    lines = raw_text.split('\n')
    
    # [ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ - AI ë¶„ì„ìš© í† í° ì ˆì•½]
    blacklist = ["V. íšŒê³„ê°ì‚¬ì¸", "VI. ì´ì‚¬íšŒ", "X. ëŒ€ì£¼ì£¼", "XII. ìƒì„¸í‘œ"]
    all_markers = [
        "I. íšŒì‚¬ì˜ ê°œìš”", "II. ì‚¬ì—…ì˜ ë‚´ìš©", "III. ì¬ë¬´ì— ê´€í•œ ì‚¬í•­",
        "IV. ì´ì‚¬ì˜ ì§„ë‹¨", "V. íšŒê³„ê°ì‚¬ì¸", "VI. ì´ì‚¬íšŒ", "VII. ì£¼ì£¼ì— ê´€í•œ ì‚¬í•­",
        "VIII. ì„ì› ë° ì§ì›", "IX. ê³„ì—´íšŒì‚¬", "X. ëŒ€ì£¼ì£¼", "XI. ê·¸ ë°–ì— íˆ¬ìì ë³´í˜¸",
        "XII. ìƒì„¸í‘œ", "ã€", "ì²¨ë¶€ì„œë¥˜"
    ]

    extracted_lines = []
    skip_mode = False
    for line in lines:
        clean_line = line.strip()
        if any(clean_line.startswith(m) for m in all_markers):
            skip_mode = any(clean_line.startswith(b) for b in blacklist)
                
        if not skip_mode: 
            extracted_lines.append(line)
            
    filtered_text = "\n".join(extracted_lines)
    filtered_text = re.sub(r' +', ' ', filtered_text)
    filtered_text = re.sub(r'\n\s*\n+', '\n\n', filtered_text)
    filtered_text = re.sub(r'[-=+#]{5,}', '', filtered_text)
    return filtered_text.strip()

# --- 5. UI êµ¬ì„± ---
with st.container(border=True):
    col_input, col_btn = st.columns([4, 1])
    with col_input:
        corp_name_input = st.text_input("íšŒì‚¬ëª… ë˜ëŠ” 6ìë¦¬ ì¢…ëª©ì½”ë“œ ì…ë ¥", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì ë˜ëŠ” 005930", label_visibility="collapsed")
    with col_btn:
        btn_start = st.button("ê²€ìƒ‰", type="primary", use_container_width=True)

    with st.expander("ğŸ“… ì„¤ì •", expanded=True):
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            start_year = st.number_input("ì‹œì‘", 2000, 2030, 2024)
        with col2:
            end_year = st.number_input("ì¢…ë£Œ", 2000, 2030, 2025)
        with col3:
            report_options = ["1ë¶„ê¸°ë³´ê³ ì„œ", "ë°˜ê¸°ë³´ê³ ì„œ", "3ë¶„ê¸°ë³´ê³ ì„œ", "ì‚¬ì—…ë³´ê³ ì„œ"]
            selected_types = st.multiselect("ì¢…ë¥˜", report_options, default=["ì‚¬ì—…ë³´ê³ ì„œ"])

# --- 6. ì‹¤í–‰ ë¡œì§ ---
if btn_start:
    if not corp_name_input:
        st.warning("íšŒì‚¬ëª… ë˜ëŠ” 6ìë¦¬ ì¢…ëª©ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    start_date = f"{start_year}0101"
    end_date = f"{end_year}1231"
    
    with st.spinner(f"ğŸ“¡ '{corp_name_input}' ê³µì‹œ ëª©ë¡ì„ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            result = fetch_report_list_direct(corp_name_input.strip(), start_date, end_date)
            
            if result is not None:
                raw_df, actual_corp_name = result
            else:
                raw_df, actual_corp_name = None, corp_name_input

            if raw_df is not None and len(raw_df) > 0:
                df = classify_and_filter(raw_df, selected_types)
                
                if not df.empty:
                    st.success(f"âœ… ì´ {len(df)}ê±´ ê²€ìƒ‰! ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ê¸°ì—…ëª…: {actual_corp_name})")
                    st.dataframe(df[['rcept_dt', 'report_nm', 'smart_type']], use_container_width=True, hide_index=True)
                    
                    with st.status("ğŸš€ í…ìŠ¤íŠ¸ ë³€í™˜ ë° ZIP ìƒì„± ì¤‘...", expanded=True) as status:
                        zip_buffer = io.BytesIO()
                        headers_download = {'User-Agent': 'Mozilla/5.0'}
                        total = len(df)

                        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
                            for i, (idx, row) in enumerate(df.iterrows()):
                                
                                rpt_name = row['report_nm']
                                fname = re.sub(r'[\\/*?:"<>|]', "", f"{actual_corp_name}_{rpt_name}.txt")
                                
                                status.write(f"ğŸ“¥ ({i+1}/{total}) ì €ì¥: {fname}")
                                
                                try:
                                    d_url = f"https://opendart.fss.or.kr/api/document.xml?crtfc_key={api_key}&rcept_no={row['rcept_no']}"
                                    res = requests.get(d_url, headers=headers_download, timeout=15)
                                    with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                                        t_file = max(z.infolist(), key=lambda f: f.file_size).filename
                                        content = z.read(t_file).decode('utf-8', 'ignore')
                                        final_txt = extract_ai_friendly_text(content)
                                        
                                        header_info = f"### {actual_corp_name} {rpt_name} ###\n"
                                        header_info += f"ì ‘ìˆ˜ì¼: {row['rcept_dt']}\n"
                                        header_info += f"ë¶„ë¥˜: {row['smart_type']}\n\n"
                                        
                                        zip_file.writestr(fname, header_info + final_txt)
                                except Exception as e:
                                    status.write(f"âš ï¸ ì‹¤íŒ¨: {fname}")
                        
                        status.update(label="ğŸ‰ ìƒì„± ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.", state="complete", expanded=False)
                    
                    if start_year == end_year:
                        year_str = f"{start_year}"
                    else:
                        year_str = f"{start_year}-{end_year}"
                    
                    if len(selected_types) == 1:
                        type_str = selected_types[0]
                    elif len(selected_types) <= 2:
                        type_str = "+".join(selected_types)
                    else:
                        type_str = "ë‹¤ì¢…ë³´ê³ ì„œ"

                    final_zip_name = f"{actual_corp_name}_{year_str}_{type_str}_ëª¨ìŒ.zip"

                    st.download_button(
                        label=f"ğŸ’¾ {final_zip_name} ì €ì¥",
                        data=zip_buffer.getvalue(),
                        file_name=final_zip_name,
                        mime="application/zip",
                        type="primary",
                        use_container_width=True
                    )
                    
                else:
                    st.warning("ì¡°ê±´ì— ë§ëŠ” ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error("âŒ ê²€ìƒ‰ëœ ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
