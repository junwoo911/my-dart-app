import streamlit as st
import OpenDartReader
import pandas as pd
import io
import zipfile
import re
import requests
import json
from bs4 import BeautifulSoup

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", 
    page_icon="ğŸ“¥", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

st.title("ğŸ“¥ ê¸°ì—… ë³´ê³ ì„œ ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ (Direct Mode)")

# --- 1. API í‚¤ ì„¤ì • ---
if 'api_key' not in st.session_state:
    if "dart_api_key" in st.secrets:
        st.session_state.api_key = st.secrets["dart_api_key"]
    else:
        st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. secrets.tomlì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

api_key = st.session_state.api_key

# --- 2. [í•µì‹¬] DART ì§ì ‘ ì ‘ì† í•¨ìˆ˜ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì‚¬ìš©) ---
# ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê±°ì¹˜ì§€ ì•Šê³  ì§ì ‘ ë¸Œë¼ìš°ì €ì¸ ì²™ í†µì‹ í•©ë‹ˆë‹¤.
@st.cache_data(ttl=600)
def fetch_report_list_direct(corp_name, start_date, end_date):
    # 1. ê³ ìœ ë²ˆí˜¸(corp_code)ë¥¼ ì•Œì•„ë‚´ê¸° ìœ„í•´ OpenDartReaderë¥¼ ì ì‹œ ì”ë‹ˆë‹¤.
    # (ì´ê±´ XML íŒŒì¼ì„ ë°›ì•„ì˜¤ëŠ” ê±°ë¼ ì°¨ë‹¨ì´ ëœí•©ë‹ˆë‹¤)
    try:
        dart = OpenDartReader(api_key)
        corp_code = dart.find_corp_code(corp_name)
        if not corp_code:
            return None
    except:
        return None

    # 2. ì‹¤ì œ ê³µì‹œ ëª©ë¡ ìš”ì²­ (ì—¬ê¸°ê°€ ì°¨ë‹¨ë˜ëŠ” êµ¬ê°„ì…ë‹ˆë‹¤)
    url = "https://opendart.fss.or.kr/api/list.json"
    params = {
        'crtfc_key': api_key,
        'corp_code': corp_code,
        'bgn_de': start_date,
        'end_de': end_date,
        'pblntf_detail_ty': 'A001', # A001: ì •ê¸°ê³µì‹œ (ì‚¬ì—…,ë°˜ê¸°,ë¶„ê¸°)
        'page_count': 100
    }
    
    # ê°•ë ¥í•œ ìœ„ì¥ í—¤ë”
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://dart.fss.or.kr/',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'Connection': 'keep-alive'
    }

    try:
        # íƒ€ì„ì•„ì›ƒ 10ì´ˆ ì„¤ì • (ë¬´í•œ ë¡œë”© ë°©ì§€)
        resp = requests.get(url, params=params, headers=headers, timeout=10)
        data = resp.json()
        
        if data.get('status') == '000':
            df = pd.DataFrame(data['list'])
            return df
        else:
            return None
    except Exception as e:
        # ì—ëŸ¬ ë‚´ìš©ì„ ë°˜í™˜í•´ì„œ í™”ë©´ì— ì°ì–´ì¤ë‹ˆë‹¤
        raise Exception(f"ì ‘ì† ì‹¤íŒ¨: {str(e)}")

# --- 3. í…ìŠ¤íŠ¸ ë³€í™˜ í•¨ìˆ˜ ---
def extract_ai_friendly_text(html_content):
    soup = BeautifulSoup(html_content, "html.parser")
    for s in soup(["script", "style", "head", "svg", "img"]):
        s.decompose()
    for table in soup.find_all("table"):
        rows = []
        headers = [th.get_text(strip=True) for th in table.find_all("th")]
        if headers:
            rows.append("| " + " | ".join(headers) + " |")
            rows.append("| " + " | ".join(["---"] * len(headers)) + " |")
        for tr in table.find_all("tr"):
            cells = [td.get_text(strip=True) for td in tr.find_all("td")]
            if cells:
                rows.append("| " + " | ".join(cells) + " |")
        table_md = "\n" + "\n".join(rows) + "\n"
        table.replace_with(table_md)
    text = soup.get_text(separator="\n")
    return re.sub(r'\n\s*\n+', '\n\n', text).strip()

# --- 4. UI êµ¬ì„± ---
with st.container(border=True):
    col_input, col_btn = st.columns([4, 1])
    with col_input:
        corp_name = st.text_input("íšŒì‚¬ëª… ì…ë ¥", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì", label_visibility="collapsed")
    with col_btn:
        btn_search = st.button("ê²€ìƒ‰", type="primary", use_container_width=True)

    with st.expander("ğŸ“… ì„¤ì •", expanded=True):
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            start_year = st.number_input("ì‹œì‘", 2000, 2030, 2024)
        with col2:
            end_year = st.number_input("ì¢…ë£Œ", 2000, 2030, 2025)
        with col3:
            report_options = ["1ë¶„ê¸°ë³´ê³ ì„œ", "ë°˜ê¸°ë³´ê³ ì„œ", "3ë¶„ê¸°ë³´ê³ ì„œ", "ì‚¬ì—…ë³´ê³ ì„œ"]
            selected_types = st.multiselect("ì¢…ë¥˜", report_options, default=["ì‚¬ì—…ë³´ê³ ì„œ"])

# --- 5. ì‹¤í–‰ ë¡œì§ ---
if btn_search or ('target_df' in st.session_state and st.session_state.target_df is not None):
    if btn_search:
        if not corp_name:
            st.warning("íšŒì‚¬ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        start_date = f"{start_year}0101"
        end_date = f"{end_year}1231"
        
        with st.spinner(f"ğŸš€ '{corp_name}' DART ì„œë²„ ëš«ëŠ” ì¤‘... (10ì´ˆ íƒ€ì„ì•„ì›ƒ)"):
            try:
                # ì§ì ‘ ë§Œë“  í•¨ìˆ˜ í˜¸ì¶œ
                df = fetch_report_list_direct(corp_name, start_date, end_date)
                
                if df is not None and len(df) > 0:
                    conditions = []
                    # í•„í„°ë§ ë¡œì§
                    if "ì‚¬ì—…ë³´ê³ ì„œ" in selected_types: conditions.append(df['report_nm'].str.contains("ì‚¬ì—…ë³´ê³ ì„œ"))
                    if "ë°˜ê¸°ë³´ê³ ì„œ" in selected_types: conditions.append(df['report_nm'].str.contains("ë°˜ê¸°ë³´ê³ ì„œ"))
                    if "1ë¶„ê¸°ë³´ê³ ì„œ" in selected_types: conditions.append(df['report_nm'].str.contains(r"ë¶„ê¸°ë³´ê³ ì„œ.*[30]3ì›”|[1]ë¶„ê¸°"))
                    if "3ë¶„ê¸°ë³´ê³ ì„œ" in selected_types: conditions.append(df['report_nm'].str.contains(r"ë¶„ê¸°ë³´ê³ ì„œ.*[0]9ì›”|[3]ë¶„ê¸°"))

                    if conditions:
                        final_mask = pd.concat(conditions, axis=1).any(axis=1)
                        filtered_df = df[final_mask].copy().reset_index(drop=True)
                    else:
                        filtered_df = pd.DataFrame()

                    st.session_state.target_df = filtered_df
                    st.session_state.current_corp = corp_name
                else:
                    st.error("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.session_state.target_df = None
            except Exception as e:
                st.error(f"âš ï¸ ì—°ê²° ì˜¤ë¥˜: {e}")
                st.caption("DART ì„œë²„ê°€ í•´ì™¸(Streamlit) ì ‘ì†ì„ ì°¨ë‹¨í–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")

    # ê²°ê³¼ ë° ë‹¤ìš´ë¡œë“œ
    if 'target_df' in st.session_state and st.session_state.target_df is not None:
        df = st.session_state.target_df
        corp_name_fixed = st.session_state.get('current_corp', corp_name)
        
        st.divider()
        st.subheader(f"âœ… ê²€ìƒ‰ ê²°ê³¼ ({len(df)}ê±´)")
        st.dataframe(df[['rcept_dt', 'report_nm']], use_container_width=True, hide_index=True)
        
        if len(df) > 0:
            if st.button("ZIP ë‹¤ìš´ë¡œë“œ ìƒì„±", type="primary"):
                zip_buffer = io.BytesIO()
                progress = st.progress(0)
                status = st.empty()
                
                headers_download = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                }

                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
                    for i, row in df.iterrows():
                        fname = re.sub(r'[\\/*?:"<>|]', "", f"{corp_name_fixed}_{row['report_nm']}.txt")
                        status.info(f"ë‹¤ìš´ë¡œë“œ ì¤‘: {fname}")
                        try:
                            # ë‹¤ìš´ë¡œë“œë„ requests ì§ì ‘ ì‚¬ìš©
                            d_url = f"https://opendart.fss.or.kr/api/document.xml?crtfc_key={api_key}&rcept_no={row['rcept_no']}"
                            res = requests.get(d_url, headers=headers_download, timeout=15)
                            
                            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                                t_file = max(z.infolist(), key=lambda f: f.file_size).filename
                                content = z.read(t_file).decode('utf-8', 'ignore')
                                final_txt = extract_ai_friendly_text(content)
                                zip_file.writestr(fname, final_txt)
                        except:
                            pass
                        progress.progress((i+1)/len(df))
                
                status.success("ì™„ë£Œ!")
                st.download_button("ğŸ’¾ íŒŒì¼ ì €ì¥", zip_buffer.getvalue(), f"{corp_name_fixed}.zip", "application/zip")
