import streamlit as st
import OpenDartReader
import pandas as pd
import io
import zipfile
import re
import requests
from bs4 import BeautifulSoup
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# --- [í•„ìˆ˜] ì‚¬ì´ë“œë°” ì ‘ê¸° ì„¤ì • ---
st.set_page_config(
    page_title="ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", 
    page_icon="ğŸ“¥", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- [í•µì‹¬ íŒ¨ì¹˜] DART ì„œë²„ ì ‘ì† ëš«ê¸° (User-Agent ìœ„ì¥) ---
# ì´ ë¶€ë¶„ì´ ì—†ìœ¼ë©´ í•´ì™¸ ì„œë²„ì—ì„œ ì ‘ì† ì‹œ ë¬´í•œ ë¡œë”©ì´ ê±¸ë¦½ë‹ˆë‹¤.
def patch_request_headers():
    default_headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': '*/*',
        'Connection': 'keep-alive'
    }
    return default_headers

# --- 1. API í‚¤ ì„¤ì • ---
st.title("ğŸ“¥ ê¸°ì—… ë³´ê³ ì„œ ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ")

if 'api_key' not in st.session_state:
    if "dart_api_key" in st.secrets:
        st.session_state.api_key = st.secrets["dart_api_key"]
    else:
        st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. secrets.tomlì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

api_key = st.session_state.api_key

# --- 2. DART ê°ì²´ ìƒì„± (ì•ˆì „ì¥ì¹˜ ì¶”ê°€) ---
@st.cache_resource
def get_dart_system(key):
    # DART ê°ì²´ ìƒì„± ì‹œì—ëŠ” ë³„ë„ í—¤ë” ì„¤ì •ì´ ì–´ë ¤ìš°ë¯€ë¡œ, 
    # ì²« ì‹¤í–‰ ì‹œ ë°ì´í„° ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ë„ì›ë‹ˆë‹¤.
    return OpenDartReader(key)

# --- 3. ë³´ê³ ì„œ ëª©ë¡ ì¡°íšŒ (ê°•ì œ íƒ€ì„ì•„ì›ƒ ë° ì¬ì‹œë„ ì ìš©) ---
@st.cache_data(ttl=3600)
def fetch_report_list_safe(corp_name, start_date, end_date):
    # 1. OpenDartReader ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    dart = get_dart_system(api_key)
    
    # 2. ì§ì ‘ ì½”ë“œë¥¼ ì°¾ì•„ì„œ ìš”ì²­ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ ë¡œì§ì´ ë©ˆì¶œ ìˆ˜ ìˆì–´ì„œ ìš°íšŒ)
    # GKL ê°™ì€ ì˜ë¬¸ëª…ì´ë‚˜ ì‚¬ëª… ê²€ìƒ‰ì„ ìœ„í•´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ëŠ¥ ì‹œë„
    try:
        # User-Agent ê°•ì œ ì ìš©ì„ ìœ„í•´ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì „ì—­ ì„¤ì • ì—…ë°ì´íŠ¸
        requests.utils.default_headers().update(patch_request_headers())
        
        # ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        return dart.list(corp_name, start=start_date, end=end_date, kind='A')
    except Exception as e:
        # í˜¹ì‹œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë©ˆì¶”ë©´ ì—ëŸ¬ë¥¼ ë°˜í™˜
        return None

# --- 4. í…ìŠ¤íŠ¸ ë³€í™˜ í•¨ìˆ˜ ---
def extract_ai_friendly_text(html_content):
    soup = BeautifulSoup(html_content, "html.parser")
    for s in soup(["script", "style", "head", "svg", "img"]):
        s.decompose()
    for table in soup.find_all("table"):
        rows = []
        headers = [th.get_text(strip=True) for th in table.find_all("th")]
        if headers:
            rows.append("| " + " | ".join(headers) + " |")
            rows.append("| " + " | ".join(["---"] * len(headers)) + " |")
        for tr in table.find_all("tr"):
            cells = [td.get_text(strip=True) for td in tr.find_all("td")]
            if cells:
                rows.append("| " + " | ".join(cells) + " |")
        table_md = "\n" + "\n".join(rows) + "\n"
        table.replace_with(table_md)
    text = soup.get_text(separator="\n")
    return re.sub(r'\n\s*\n+', '\n\n', text).strip()

# --- 5. UI êµ¬ì„± ---
with st.container(border=True):
    col_input, col_btn = st.columns([4, 1])
    with col_input:
        corp_name = st.text_input("íšŒì‚¬ëª… ì…ë ¥", placeholder="ì˜ˆ: GKL, ì‚¼ì„±ì „ì", label_visibility="collapsed")
    with col_btn:
        btn_search = st.button("ê²€ìƒ‰", type="primary", use_container_width=True)

    with st.expander("ğŸ“… ê¸°ê°„ ë° ë³´ê³ ì„œ ì¢…ë¥˜ (ê¸°ë³¸ê°’: ìµœê·¼ 1ë…„, ì‚¬ì—…ë³´ê³ ì„œ)", expanded=True):
        opt_col1, opt_col2, opt_col3 = st.columns([1, 1, 2])
        with opt_col1:
            start_year = st.number_input("ì‹œì‘ ì—°ë„", min_value=1990, max_value=2030, value=2024, step=1)
        with opt_col2:
            end_year = st.number_input("ì¢…ë£Œ ì—°ë„", min_value=1990, max_value=2030, value=2025, step=1)
        with opt_col3:
            report_options = ["1ë¶„ê¸°ë³´ê³ ì„œ", "ë°˜ê¸°ë³´ê³ ì„œ", "3ë¶„ê¸°ë³´ê³ ì„œ", "ì‚¬ì—…ë³´ê³ ì„œ"]
            selected_types = st.multiselect("ì¢…ë¥˜", report_options, default=["ì‚¬ì—…ë³´ê³ ì„œ"], label_visibility="collapsed")

# --- 6. ì‹¤í–‰ ë¡œì§ ---
if btn_search or ('target_df' in st.session_state and st.session_state.target_df is not None):
    if btn_search:
        if not corp_name:
            st.warning("íšŒì‚¬ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        start_date = f"{start_year}0101"
        end_date = f"{end_year}1231"
        
        # ìŠ¤í”¼ë„ˆì— ë©”ì‹œì§€ êµ¬ì²´í™”
        with st.spinner(f"ğŸ“¡ '{corp_name}' ì ‘ì† ì‹œë„ ì¤‘... (ì²« ê²€ìƒ‰ì€ 20~30ì´ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
            try:
                # íƒ€ì„ì•„ì›ƒ ê±¸ë¦° ìš”ì²­ ì‹¤í–‰
                df = fetch_report_list_safe(corp_name, start_date, end_date)
                
                if df is not None and len(df) > 0:
                    conditions = []
                    if "ì‚¬ì—…ë³´ê³ ì„œ" in selected_types: conditions.append(df['report_nm'].str.contains("ì‚¬ì—…ë³´ê³ ì„œ"))
                    if "ë°˜ê¸°ë³´ê³ ì„œ" in selected_types: conditions.append(df['report_nm'].str.contains("ë°˜ê¸°ë³´ê³ ì„œ"))
                    if "1ë¶„ê¸°ë³´ê³ ì„œ" in selected_types:
                        conditions.append((df['report_nm'].str.contains("ë¶„ê¸°ë³´ê³ ì„œ")) & (df['report_nm'].str.contains(r"\.03|\.3ì›”", regex=True)))
                    if "3ë¶„ê¸°ë³´ê³ ì„œ" in selected_types:
                        conditions.append((df['report_nm'].str.contains("ë¶„ê¸°ë³´ê³ ì„œ")) & (df['report_nm'].str.contains(r"\.09|\.9ì›”", regex=True)))

                    if conditions:
                        final_mask = pd.concat(conditions, axis=1).any(axis=1)
                        filtered_df = df[final_mask].copy().reset_index(drop=True)
                    else:
                        filtered_df = pd.DataFrame()

                    st.session_state.target_df = filtered_df
                    st.session_state.current_corp = corp_name
                else:
                    st.error("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ DART ì„œë²„ ì‘ë‹µì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
                    st.session_state.target_df = None
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ
    if 'target_df' in st.session_state and st.session_state.target_df is not None:
        df = st.session_state.target_df
        corp_name_fixed = st.session_state.get('current_corp', corp_name)
        
        st.divider()
        st.subheader(f"âœ… ê²€ìƒ‰ ê²°ê³¼ ({len(df)}ê±´)")
        st.dataframe(df[['rcept_dt', 'report_nm']], use_container_width=True, hide_index=True)
        
        if len(df) > 0:
            if st.button("ğŸš€ ì „ì²´ ë‹¤ìš´ë¡œë“œ (ZIP)", type="primary", use_container_width=True):
                zip_buffer = io.BytesIO()
                progress_bar = st.progress(0)
                status_text = st.empty()
                total = len(df)
                
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
                    for idx, row in df.iterrows():
                        report_name = row['report_nm']
                        file_name = f"{corp_name_fixed}_{report_name}.txt"
                        file_name = re.sub(r'[\\/*?:"<>|]', "", file_name)
                        
                        status_text.info(f"â³ ({idx+1}/{total}) {file_name} ì¶”ì¶œ ì¤‘...")
                        
                        try:
                            # ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì—ë„ í—¤ë” ì ìš©
                            url = f"https://opendart.fss.or.kr/api/document.xml?crtfc_key={api_key}&rcept_no={row['rcept_no']}"
                            # requests.get ì‚¬ìš© ì‹œ headers ì¶”ê°€
                            res = requests.get(url, timeout=15, headers=patch_request_headers())
                            
                            with zipfile.ZipFile(io.BytesIO(res.content)) as z_orig:
                                target_file = max(z_orig.infolist(), key=lambda f: f.file_size).filename
                                raw_data = z_orig.read(target_file)
                                try: content_html = raw_data.decode('utf-8')
                                except: content_html = raw_data.decode('euc-kr', 'ignore')
                                clean_text = extract_ai_friendly_text(content_html)
                                
                                final_content = f"### {corp_name_fixed} {report_name} ###\nì ‘ìˆ˜ì¼: {row['rcept_dt']}\n\n{clean_text}"
                                zip_file.writestr(file_name, final_content)
                        except Exception as e:
                            st.error(f"ì‹¤íŒ¨: {file_name}")
                        progress_bar.progress((idx + 1) / total)

                status_text.success("ì™„ë£Œ! ë²„íŠ¼ì„ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”.")
                st.download_button(
                    label="ğŸ’¾ ZIP íŒŒì¼ ì €ì¥í•˜ê¸°",
                    data=zip_buffer.getvalue(),
                    file_name=f"{corp_name_fixed}_Reports.zip",
                    mime="application/zip",
                    type="primary",
                    use_container_width=True
                )
